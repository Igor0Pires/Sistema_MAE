{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22b1a7b8",
   "metadata": {},
   "source": [
    "# Criação de um template do excel para manipulação de dados\n",
    "Este template será substituído posteriormente pela tabela que de fato corresponde aos cursos e trilhas do datacamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7c87812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id_trilha       nome_trilha  id_curso              nome_curso  ordem_curso\n",
      "0          0  Data Engineering         2                     SQL            0\n",
      "1          1      Data Science         0  Introduction to Python            0\n",
      "2          1      Data Science         1     Intermediate Python            1\n",
      "5          2     Trilha FeaDev         2                     SQL            0\n",
      "3          2     Trilha FeaDev         0  Introduction to Python            1\n",
      "4          2     Trilha FeaDev         1     Intermediate Python            2\n",
      "✅ Arquivo Excel salvo com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "membros_feadev = pd.DataFrame({\n",
    "        'id_membro': [0, 1, 2],\n",
    "        'nome': ['admin', 'Tiago Toledo', 'Rogério Ceni'],\n",
    "        'email': ['email-falso-admin-dev@gmail.com', 'ttduarte@usp.br', 'rogerio-ceni@gmail.com'],\n",
    "        'conta_github': ['admin-feadev-github', 'Tiago745', 'Rogerio-Ceni-Github'],\n",
    "        'conta_datacamp': ['', '', ''], #provavelmente será uma url para cursos finalizados, ainda precisa ser revisado\n",
    "        'xp_datacamp': ['', '', '']\n",
    "})\n",
    "\n",
    "trilhas = pd.DataFrame({\n",
    "        'id_trilha': [0, 1, 2], #chave/id/pk\n",
    "        'nome_trilha': ['Data Engineering', 'Data Science', 'Trilha FeaDev'],\n",
    "        'url': [\"https://app.datacamp.com/learn/career-tracks/associate-data-engineer-in-sql\", \"https://app.datacamp.com/learn/career-tracks/associate-data-scientist-in-python\",''],\n",
    "        'tipo_trilha': [0,0,1] # 0-> trilha do datacamp || 1-> trilha personalizada (default deve ser 0, 1 somente quando for personalizado ou criado in-app)\n",
    "        })\n",
    "\n",
    "cursos = pd.DataFrame({\n",
    "    'id_curso': [0, 1, 2],\n",
    "    'nome_curso': ['Introduction to Python', 'Intermediate Python', 'SQL']\n",
    "})\n",
    "\n",
    "\n",
    "#DataFrames Associativos\n",
    "trilhas_tem_cursos = pd.DataFrame({\n",
    "    'id_trilha' : [1, 1, 0, 2, 2, 2],\n",
    "    'id_curso' : [0, 1, 2, 0, 1, 2],\n",
    "    'ordem_curso' : [0, 1, 0, 1, 2, 0], #ordem em que os cursos devem ser assistidos dentro de cada trilha\n",
    "    'data_final_para_assistir': ['', '', '','20/06/2023', '20/06/2023', '23/06/2023'], #cursos de trilhas do datacamp nao tem data-final, apenas trilhas personalizadas\n",
    "    'obrigatoriedade_curso': [1, 1, 1, 1, 1, 1] #o curso precisa ser obrigatoriamente assistido ou é opcional, 1->Obrigatório 0->Não obrigatório/opcional\n",
    "})\n",
    "\n",
    "membro_feadev_faz_trilhas = pd.DataFrame({\n",
    "    'id_membro' : [1],\n",
    "    'id_trilha' : [2],\n",
    "    'data_inicio' : ['15/06/2025'],\n",
    "    'data_fim' : ['20/06/2025'],\n",
    "    'finalizado' : [True]\n",
    "})\n",
    "\n",
    "membro_feadev_faz_cursos = pd.DataFrame({\n",
    "    'id_membro' : [1, 1, 1],\n",
    "    'id_curso' : [0,1,2],\n",
    "    'data_inicio' : ['15/06/2025', '17/06/2025', '20/06/2025'],\n",
    "    'data_fim' : ['15/06/2025', '21/06/2025', '21/06/2025'],\n",
    "    'finalizado' : [True, True, True]\n",
    "})\n",
    "\n",
    "#Uniao de trilhas com cursos\n",
    "resultado = trilhas.merge(trilhas_tem_cursos, on='id_trilha') \\\n",
    "                   .merge(cursos, on='id_curso') \\\n",
    "                   #[['id_trilha', 'nome_trilha', 'id_curso', 'nome_curso']]  # remove colunas extras\n",
    "\n",
    "resultado_ordenado = resultado.sort_values(by=['id_trilha', 'ordem_curso']) #ordena por trilha e depois por ordem que deve assistir cada curso, facilita a leitura\n",
    "\n",
    "print(resultado_ordenado[['id_trilha', 'nome_trilha', 'id_curso', 'nome_curso', 'ordem_curso']])\n",
    "\n",
    "\n",
    "# Caminho do arquivo Excel que será salvo\n",
    "arquivo_excel = 'dados_trilhas.xlsx'\n",
    "\n",
    "# Usando o ExcelWriter para salvar cada DataFrame em uma aba diferente\n",
    "with pd.ExcelWriter('arquivo.xlsx', engine='openpyxl') as writer:\n",
    "    trilhas.to_excel(writer, sheet_name='Trilhas', index=False)\n",
    "    cursos.to_excel(writer, sheet_name='Cursos', index=False)\n",
    "    trilhas_tem_cursos.to_excel(writer, sheet_name='Trilhas_tem_Cursos', index=False)\n",
    "    membros_feadev.to_excel(writer, sheet_name='Membros_feadev', index=False)\n",
    "    membro_feadev_faz_trilhas.to_excel(writer, sheet_name='membro_feadev_faz_trilhas', index=False)\n",
    "    membro_feadev_faz_cursos.to_excel(writer, sheet_name='membro_feadev_faz_cursos', index=False)\n",
    "\n",
    "print(\"✅ Arquivo Excel salvo com sucesso!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ad3e9",
   "metadata": {},
   "source": [
    "# Placeholder de Webscrapping (ainda não implementado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54e25cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n",
      "200\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 154\u001b[39m\n\u001b[32m    151\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m✅ Cursos extraídos com sucesso.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccess_with_cookies\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\asyncio\\runners.py:186\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    182\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    183\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    187\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    190\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from cloudscraper import create_scraper # biblioteca para contornar proteção de sites que usam Cloudflare\n",
    "from bs4 import BeautifulSoup\n",
    "from playwright.async_api import async_playwright # biblioteca para automação de navegadores\n",
    "\n",
    "import json \n",
    "import random\n",
    "import pickle # biblioteca para salvar e carregar objetos Python em arquivos\n",
    "import asyncio\n",
    "import requests\n",
    "\n",
    "scraper = create_scraper()\n",
    "\n",
    "urls_courses = [\"https://app.datacamp.com/learn/career-tracks/associate-data-engineer-in-sql\", \"https://app.datacamp.com/learn/career-tracks/associate-data-scientist-in-python\"]\n",
    "urls_skills = [\"https://app.datacamp.com/certification/get-started/data-engineer-associate/overview\", \"https://app.datacamp.com/certification/get-started/associate-data-scientist/overview\"]\n",
    "\n",
    "\n",
    "response = requests.get(urls_courses[0])\n",
    "print(response.status_code) # erro 403: Forbidden, indica que a requisição foi negada pelo servidor\n",
    "\n",
    "response = scraper.get(urls_courses[0]) # usando o scraper para contornar a proteção do site\n",
    "print(response.status_code) # agora deve retornar 200, indicando sucesso\n",
    "\n",
    "# soup = BeautifulSoup(response.text, \"html.parser\") # analisa o HTML da página\n",
    "# print(soup.prettify()) # imprime o HTML formatado \n",
    "\n",
    "semaphore = asyncio.Semaphore(5) # Limita o número de páginas abertas simultaneamente para 5\n",
    "\n",
    "# extrair o conteudo das habilidades de cada trilha\n",
    "async def extract_skills(context, url):\n",
    "    async with semaphore:\n",
    "        page = await context.new_page()\n",
    "        try: # tenta acessar a página\n",
    "            await page.goto(url, timeout=60000)\n",
    "            await asyncio.sleep(random.uniform(2, 4))\n",
    "            \n",
    "            if \"just a moment\" not in (await page.content()).lower(): # Verifica se a página não foi redirecionada para uma página de proteção\n",
    "                soup = BeautifulSoup(await page.content(), \"html.parser\") # analisa o HTML da página\n",
    "                \n",
    "                skills = list(set([skills.get_text(strip=True) # extrai as habilidades (sem duplicatas)\n",
    "                        for skills in soup.select(\"section ul span\")])) # (section ul span) é o seletor CSS que localiza as habilidades\n",
    "                \n",
    "                track_element = soup.find(\"h1\") # localiza o elemento que contém o nome da trilha\n",
    "                track = track_element.get_text(strip=True) if track_element else \"N/A\" # extrai o texto do elemento, se encontrado\n",
    "\n",
    "                data = []\n",
    "                for skill in skills:\n",
    "                    data.append({\"track\": track, \"skill\": skill})# cria um dicionário com a trilha e a habilidade\n",
    "                return data\n",
    "            \n",
    "            else:\n",
    "                print(\"❌ Falha: Cookies expirados ou inválidos. Repita o login manual.\")\n",
    "                return None\n",
    "        except Exception as e: # se ocorrer um erro ao acessar a página\n",
    "            print(f\"❌ Erro ao extrair habilidades da página {url}: {e}\")\n",
    "            return None\n",
    "        finally: # garante que a página será fechada\n",
    "            await page.close()\n",
    "            print(f\"✅ Página {url} fechada.\")\n",
    "\n",
    "# extrair o conteudo dos cursos de cada trilha\n",
    "async def extract_courses(context, url):\n",
    "    async with semaphore:\n",
    "        page = await context.new_page()\n",
    "        try:\n",
    "            await page.goto(url, timeout=60000)\n",
    "            await asyncio.sleep(random.uniform(2, 4)) # espera um tempo aleatório entre 2 e 4 segundos para evitar bloqueios por parte do site\n",
    "            \n",
    "            if \"just a moment\" not in (await page.content()).lower():\n",
    "                soup = BeautifulSoup(await page.content(), \"html.parser\")\n",
    "\n",
    "                track_element = soup.find(\"h1\")\n",
    "                track = track_element.get_text(strip=True) if track_element else \"N/A\"\n",
    "\n",
    "                projects = {optional.find_parent('div') for optional in soup.select(\".mfe-app-learn-hub-1moscjt\")} # projetos opcionais do curso o \".mfe-app-learn-hub-1moscjt\" é o seletor CSS que localiza os projetos\n",
    "\n",
    "                courses = list(set([course.get_text(strip=True) for course in soup.select(\"h3.mfe-app-learn-hub-1yqo1j7\") # h3.mfe-app-learn-hub-1yqo1j7 é o seletor CSS que localiza os cursos\n",
    "                                if course.find_parent('div') not in projects])) # extrai apenas os cursos\n",
    "                await page.close()\n",
    "                duration = {}\n",
    "                try: # tenta acessar a página de cada curso para extrair a duração\n",
    "                    for course in courses:\n",
    "                        course_page = course.replace(\" \", \"-\").lower() # formata o nome do curso para criar a URL\n",
    "                        tmp_url = f\"https://app.datacamp.com/learn/courses/{course_page}\" \n",
    "                        page = await context.new_page() \n",
    "\n",
    "                        await page.goto(tmp_url, timeout=60000)\n",
    "                        await asyncio.sleep(random.uniform(2, 3))\n",
    "\n",
    "                        soup = BeautifulSoup(await page.content(), \"html.parser\")\n",
    "\n",
    "                        duration_element = soup.select_one(\".mfe-app-learn-hub-hdd90k\")# seletor CSS que localiza a duração do curso\n",
    "                        duration[course] = duration_element.get_text(strip=True) if duration_element else \"N/A\"\n",
    "\n",
    "                        await page.close()\n",
    "\n",
    "                    print(f\"✅ Duração de curso extraídos com sucesso da página {url}.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Erro ao acessar a página do curso: {e}\")\n",
    "                    return None\n",
    "                data = []\n",
    "                for course in courses:\n",
    "                    data.append({\"track\": track, \"course\": course, \"duration\": duration[course]})\n",
    "                return data\n",
    "            else:\n",
    "                print(\"❌ Falha: Cookies expirados ou inválidos. Repita o login manual.\")\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Erro ao extrair curso da página {url}: {e}\")\n",
    "            return None\n",
    "            \n",
    "# acessar a página com cookies salvos e fazer o scraping\n",
    "async def access_with_cookies():\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True, args=[\n",
    "                \"--disable-blink-features=AutomationControlled\", # Desativa detecção de automação\n",
    "                \"--disable-web-security\"  # Ignora políticas CORS (regras de segurança que restringem o acesso a recursos entre diferentes origens)\n",
    "            ]) # Headless=True para não abrir a janela do navegador, False para abrir a janela do navegador\n",
    "        \n",
    "        # Carrega cookies\n",
    "        try:\n",
    "            with open(\"./data/cookies/datacamp_cookies.pkl\", \"rb\") as f:\n",
    "                cookies = pickle.load(f)# carrega os cookies salvos no arquivo \"datacamp_cookies.pkl\"\n",
    "        except:\n",
    "            print(\"❌ Erro: Primeiro execute get_cookies.py para salvar os cookies.\")\n",
    "            return\n",
    "        \n",
    "        context = await browser.new_context(\n",
    "            user_agent=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "            bypass_csp=True  # Contorna políticas de segurança\n",
    "        )\n",
    "        await context.add_cookies(cookies)# adiciona os cookies ao contexto do navegador\n",
    "\n",
    "        ## Cria as tarefas para extrair habilidades e cursos\n",
    "        tasks_skill = [extract_skills(context, url) for url in urls_skills]\n",
    "        tasks_courses = [extract_courses(context, url) for url in urls_courses]\n",
    "\n",
    "        ## Executa as tarefas de forma assíncrona\n",
    "        results_skill = await asyncio.gather(*tasks_skill) \n",
    "        results_courses = await asyncio.gather(*tasks_courses)\n",
    "\n",
    "        # Descompacta os resultados e converte para DataFrame\n",
    "        results_skill = [item for sublist in results_skill for item in sublist] if results_skill else []\n",
    "        results_courses = [item for sublist in results_courses for item in sublist] if results_courses else []\n",
    "\n",
    "        # Cria json com os resultados\n",
    "        with open(\"./data/processed/skills.json\", \"w\") as f:\n",
    "            json.dump(results_skill, f, indent=4)\n",
    "        print(\"✅ Habilidades extraídas com sucesso.\")\n",
    "        with open(\"./data/processed/courses.json\", \"w\") as f:\n",
    "            json.dump(results_courses, f, indent=4)\n",
    "        print(\"✅ Cursos extraídos com sucesso.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(access_with_cookies()) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
